# pock-ai-core
Native AI core for an offline mobile assistant using llama.cpp
